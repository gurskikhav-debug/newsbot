import os
import json
import requests
from datetime import datetime, timedelta
from deep_translator import GoogleTranslator
import feedparser

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
TOKEN = os.getenv("TOKEN")
NEWSAPI_KEY = os.getenv("NEWSAPI_KEY")
ADMIN_ID = os.getenv("ADMIN_ID")
KEYWORDS_INPUT = os.getenv("KEYWORDS", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∫–æ—Å–º–æ—Å, AI")  # –ò–∑ workflow

# --- –ö–µ—à ---
CACHE_FILE = "cache/news_cache.json"

def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                return set(data) if isinstance(data, list) else set()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–µ—à–∞: {e}")
    return set()

def save_cache(cache_set):
    os.makedirs("cache", exist_ok=True)
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(list(cache_set), f, ensure_ascii=False, indent=2)

# --- –ü–µ—Ä–µ–≤–æ–¥ ---
def translate_text(text):
    try:
        return GoogleTranslator(source='auto', target='ru').translate(text)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
        return text

# --- –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π ---
def search_news(keywords):
    articles = []

    # 1. NewsAPI
    if NEWSAPI_KEY:
        try:
            url = "https://newsapi.org/v2/everything"
            params = {
                'q': ' OR '.join(keywords),
                'language': 'en',
                'sortBy': 'publishedAt',
                'pageSize': 20,
                'apiKey': NEWSAPI_KEY
            }
            r = requests.get(url, params=params, timeout=15)
            if r.status_code == 200:
                data = r.json()
                for item in data.get('articles', []):
                    articles.append({
                        'title': item['title'],
                        'url': item['url'],
                        'source': item['source']['name'],
                        'published': item.get('publishedAt', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                    })
            else:
                print(f"NewsAPI error {r.status_code}: {r.text}")
        except Exception as e:
            print(f"NewsAPI –æ—à–∏–±–∫–∞: {e}")

    # 2. RSS –∏–∑ –ö–∏—Ç–∞—è
    try:
        feeds = {
            'xinhua': 'http://www.xinhuanet.com/rss/world.xml',
            'sina': 'https://rss.sina.com.cn/news/china.xml',
            'sohu': 'http://rss.news.sohu.com/rss2/news.xml'
        }
        for name, feed_url in feeds.items():
            try:
                feed = feedparser.parse(feed_url)
                for entry in feed.entries:
                    title = entry.title.lower()
                    if any(kw.lower() in title for kw in keywords):
                        articles.append({
                            'title': entry.title,
                            'url': entry.link,
                            'source': name,
                            'published': entry.get('published', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                        })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ RSS {name}: {e}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ RSS: {e}")

    # 3. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–∞–π—Ç—ã
    try:
        tech_feeds = {
            'habr': 'https://habr.com/ru/rss/technology/',
            'techcrunch': 'https://techcrunch.com/feed/',
            'wired': 'https://www.wired.com/feed/rss'
        }
        for name, feed_url in tech_feeds.items():
            try:
                feed = feedparser.parse(feed_url)
                for entry in feed.entries:
                    title = entry.title.lower()
                    if any(kw.lower() in title for kw in keywords):
                        articles.append({
                            'title': entry.title,
                            'url': entry.link,
                            'source': name,
                            'published': entry.get('published', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                        })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ RSS {name}: {e}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö RSS: {e}")

    return articles

# --- –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram ---
def send_message(chat_id, text, parse_mode='Markdown', disable_preview=False):
    if not chat_id:
        print("‚ùå chat_id –Ω–µ –∑–∞–¥–∞–Ω")
        return
    try:
        url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
        data = {
            "chat_id": chat_id,
            "text": text,
            "parse_mode": parse_mode,
            "disable_web_page_preview": not disable_preview
        }
        response = requests.post(url, data=data, timeout=10)
        if response.status_code == 200:
            print(f"‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ {chat_id}")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {response.status_code}, {response.text}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ: {e}")

# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ---
def main():
    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω (—Ä–µ–∂–∏–º GitHub Actions)")

    # –ü–∞—Ä—Å–∏–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    keywords = [kw.strip().lower() for kw in KEYWORDS_INPUT.split(',') if kw.strip()]
    print(f"üîç –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keywords}")

    if not keywords:
        print("‚ùå –ù–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞")
        return

    seen_urls = load_cache()
    raw_articles = search_news(keywords)
    print(f"–ü–æ–ª—É—á–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(raw_articles)}")

    if not raw_articles:
        print("‚ùå –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        if ADMIN_ID:
            send_message(ADMIN_ID, "‚ùå –ù–æ–≤–æ—Å—Ç–∏ –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º —Å–ª–æ–≤–∞–º –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏
    articles = [a for a in raw_articles if a.get('url') not in seen_urls]

    if not articles:
        print("–ù–æ–≤–æ—Å—Ç–∏ —É–∂–µ –±—ã–ª–∏ –ø–æ–∫–∞–∑–∞–Ω—ã —Ä–∞–Ω–µ–µ.")
        if ADMIN_ID:
            send_message(ADMIN_ID, "üì≠ –ù–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –≤–∞—à–∏–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –Ω–µ—Ç.")
        return

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–µ 10
    msg = f"üì¨ *–ù–æ–≤–æ—Å—Ç–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É:* `{', '.join(keywords)}`\n\n"
    for art in articles[:10]:
        title_ru = translate_text(art['title'])
        source = art.get('source', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        msg += f"üìå *{title_ru}*\nüåê {source}\nüîó {art['url']}\n\n"

    if ADMIN_ID:
        send_message(ADMIN_ID, msg, disable_preview=False)

    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à
    for art in articles:
        url = art.get('url')
        if url:
            seen_urls.add(url)
    save_cache(seen_urls)

    print("‚úÖ –†–∞—Å—Å—ã–ª–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

# --- –ó–∞–ø—É—Å–∫ ---
if __name__ == "__main__":
    main()
