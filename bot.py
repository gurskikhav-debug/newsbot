import os
import json
import requests
from datetime import datetime, timedelta
from deep_translator import GoogleTranslator
import feedparser
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
TOKEN = os.getenv("TOKEN")
NEWSAPI_KEY = os.getenv("NEWSAPI_KEY")
ADMIN_ID = os.getenv("ADMIN_ID")

# --- –°–æ—Å—Ç–æ—è–Ω–∏—è ---
AWAITING_KEYWORDS = "awaiting_keywords"

# --- –ö–µ—à ---
CACHE_FILE = "cache/news_cache.json"

def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                return set(data) if isinstance(data, list) else set()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–µ—à–∞: {e}")
    return set()

def save_cache(cache_set):
    os.makedirs("cache", exist_ok=True)
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(list(cache_set), f, ensure_ascii=False, indent=2)

# --- –ü–µ—Ä–µ–≤–æ–¥ ---
def translate_text(text):
    try:
        return GoogleTranslator(source='auto', target='ru').translate(text)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
        return text

# --- –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π ---
def search_news(keywords):
    articles = []

    # 1. NewsAPI
    if NEWSAPI_KEY:
        try:
            url = "https://newsapi.org/v2/everything"
            params = {
                'q': ' OR '.join(keywords),
                'language': 'en',
                'sortBy': 'publishedAt',
                'pageSize': 20,
                'apiKey': NEWSAPI_KEY
            }
            r = requests.get(url, params=params, timeout=15)
            if r.status_code == 200:
                data = r.json()
                for item in data.get('articles', []):
                    articles.append({
                        'title': item['title'],
                        'url': item['url'],
                        'source': item['source']['name'],
                        'published': item.get('publishedAt', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                    })
            else:
                print(f"NewsAPI error {r.status_code}: {r.text}")
        except Exception as e:
            print(f"NewsAPI –æ—à–∏–±–∫–∞: {e}")

    # 2. RSS –∏–∑ –ö–∏—Ç–∞—è
    try:
        feeds = {
            'xinhua': 'http://www.xinhuanet.com/rss/world.xml',
            'sina': 'https://rss.sina.com.cn/news/china.xml',
            'sohu': 'http://rss.news.sohu.com/rss2/news.xml'
        }
        for name, feed_url in feeds.items():
            try:
                feed = feedparser.parse(feed_url)
                for entry in feed.entries:
                    title = entry.title.lower()
                    if any(kw.lower() in title for kw in keywords):
                        articles.append({
                            'title': entry.title,
                            'url': entry.link,
                            'source': name,
                            'published': entry.get('published', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                        })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ RSS {name}: {e}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ RSS: {e}")

    # 3. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–∞–π—Ç—ã
    try:
        tech_feeds = {
            'habr': 'https://habr.com/ru/rss/technology/',
            'techcrunch': 'https://techcrunch.com/feed/',
            'wired': 'https://www.wired.com/feed/rss'
        }
        for name, feed_url in tech_feeds.items():
            try:
                feed = feedparser.parse(feed_url)
                for entry in feed.entries:
                    title = entry.title.lower()
                    if any(kw.lower() in title for kw in keywords):
                        articles.append({
                            'title': entry.title,
                            'url': entry.link,
                            'source': name,
                            'published': entry.get('published', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                        })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ RSS {name}: {e}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö RSS: {e}")

    return articles

# --- –ö–æ–º–∞–Ω–¥—ã ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        [InlineKeyboardButton("üîç –ù–∞–π—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏", callback_data='manual_search')],
        [InlineKeyboardButton("üìã –ü–æ–º–æ—â—å", callback_data='help')]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π.\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup=reply_markup
    )

async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    if query.data == 'manual_search':
        await query.edit_message_text("–í–≤–µ–¥–∏—Ç–µ **–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞** –¥–ª—è –ø–æ–∏—Å–∫–∞.\n–ù–∞–ø—Ä–∏–º–µ—Ä: `—Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞, 3D –ø–µ—á–∞—Ç—å`")
        context.user_data['state'] = AWAITING_KEYWORDS

    elif query.data == 'help':
        await query.edit_message_text(
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n"
            "üîç –ù–∞–π—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏ ‚Äî –∏—â–∏—Ç–µ –ø–æ —Ç–µ–º–µ\n"
            "–í—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π.\n"
            "–ü–æ–∏—Å–∫ –≤–µ–¥—ë—Ç—Å—è –ø–æ –≤—Å–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º."
        )

async def handle_keywords(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if context.user_data.get('state') != AWAITING_KEYWORDS:
        return

    keywords_input = update.message.text.strip()
    if not keywords_input:
        await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ.")
        return

    keywords = [kw.strip().lower() for kw in keywords_input.split(',') if kw.strip()]
    await update.message.reply_text(f"üîç –ò—â—É –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ: *{', '.join(keywords)}*...", parse_mode='Markdown')

    # –ü–æ–∏—Å–∫
    raw_articles = search_news(keywords)
    print(f"–ü–æ–ª—É—á–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(raw_articles)}")

    if not raw_articles:
        await update.message.reply_text("‚ùå –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        context.user_data['state'] = None
        return

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏
    seen_urls = load_cache()
    articles = [a for a in raw_articles if a.get('url') not in seen_urls]

    if not articles:
        await update.message.reply_text("–ù–æ–≤–æ—Å—Ç–∏ —É–∂–µ –±—ã–ª–∏ –ø–æ–∫–∞–∑–∞–Ω—ã —Ä–∞–Ω–µ–µ.")
        context.user_data['state'] = None
        return

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
    for art in articles[:10]:
        title_ru = translate_text(art['title'])
        source = art.get('source', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        msg = f"üìå *{title_ru}*\nüåê {source}\nüîó {art['url']}"
        await update.message.reply_text(msg, parse_mode='Markdown', disable_web_page_preview=False)

    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à
    for art in articles:
        url = art.get('url')
        if url:
            seen_urls.add(url)
    save_cache(seen_urls)

    context.user_data['state'] = None

# --- –ó–∞–ø—É—Å–∫ ---
if __name__ == "__main__":
    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –≤ —Ä–µ–∂–∏–º–µ Telegram polling")

    application = Application.builder().token(TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CallbackQueryHandler(button_handler))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_keywords))

    application.run_polling()
