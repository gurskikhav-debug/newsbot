import os
import json
import requests
from datetime import datetime, timedelta
from deep_translator import GoogleTranslator
import feedparser

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
TOKEN = os.getenv("TOKEN")
NEWSAPI_KEY = os.getenv("NEWSAPI_KEY")
ADMIN_ID = os.getenv("ADMIN_ID")

# --- –ö–µ—à ---
CACHE_FILE = "cache/news_cache.json"

def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                return set(data) if isinstance(data, list) else set()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–µ—à–∞: {e}")
    return set()

def save_cache(cache_set):
    os.makedirs("cache", exist_ok=True)
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(list(cache_set), f, ensure_ascii=False, indent=2)

# --- –ü–µ—Ä–µ–≤–æ–¥ ---
def translate_text(text):
    try:
        return GoogleTranslator(source='auto', target='ru').translate(text)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
        return text

# --- –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ) ---
KEYWORDS_EN = [
    'metallurgy', 'ferrous metallurgy', 'non-ferrous metallurgy',
    'steel production', 'metal processing', 'additive manufacturing',
    '3D printing metal', 'rare earth metals', 'refractory metals',
    'tungsten', 'molybdenum', 'titanium', 'nickel', 'aluminum',
    'copper', 'lithium', 'cobalt', 'industrial technology',
    'market analysis metals', 'steel market', 'rare earth market',
    'mining', 'industrial innovation', 'digitalization industry',
    'AI in industry', 'robotization of industry'
]

KEYWORDS_RU = [
    '–º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è', '—á–µ—Ä–Ω–∞—è –º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è', '—Ü–≤–µ—Ç–Ω–∞—è –º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è',
    '–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ —Å—Ç–∞–ª–∏', '–æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–∞–ª–ª–æ–≤', '–∞–¥–¥–∏—Ç–∏–≤–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
    '3D –ø–µ—á–∞—Ç—å –º–µ—Ç–∞–ª–ª–æ–º', '—Ä–µ–¥–∫–æ–∑–µ–º–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–ª–ª—ã', '—Ç—É–≥–æ–ø–ª–∞–≤–∫–∏–µ –º–µ—Ç–∞–ª–ª—ã',
    '–≤–æ–ª—å—Ñ—Ä–∞–º', '–º–æ–ª–∏–±–¥–µ–Ω', '—Ç–∏—Ç–∞–Ω', '–Ω–∏–∫–µ–ª—å', '–∞–ª—é–º–∏–Ω–∏–π',
    '–º–µ–¥—å', '–ª–∏—Ç–∏–π', '–∫–æ–±–∞–ª—å—Ç', '–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
    '–∞–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –º–µ—Ç–∞–ª–ª–æ–≤', '—Ä—ã–Ω–æ–∫ —Å—Ç–∞–ª–∏', '—Ä—ã–Ω–æ–∫ –†–ó–ú',
    '–≥–æ—Ä–Ω–æ–µ –¥–µ–ª–æ', '–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏', '—Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç–∏',
    '–ò–ò –≤ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç–∏', '—Ä–æ–±–æ—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç–∏'
]

ALL_KEYWORDS = KEYWORDS_RU + KEYWORDS_EN

# --- –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è ---
def search_news():
    articles = []

    # 1. NewsAPI ‚Äî —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –¥–∞—Ç–µ
    if NEWSAPI_KEY:
        # –î–∞—Ç–∞ 3 –¥–Ω—è –Ω–∞–∑–∞–¥
        from_date = (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d')

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        queries = [
            ' OR '.join(KEYWORDS_EN[:8]),
            ' OR '.join(KEYWORDS_EN[8:16]),
            ' OR '.join(KEYWORDS_EN[16:])
        ]

        for query in queries:
            try:
                url = "https://newsapi.org/v2/everything"
                params = {
                    'q': query,
                    'from': from_date,
                    'language': 'en',
                    'sortBy': 'publishedAt',
                    'pageSize': 20,
                    'apiKey': NEWSAPI_KEY
                }
                r = requests.get(url, params=params, timeout=15)
                if r.status_code == 200:
                    data = r.json()
                    for item in data.get('articles', []):
                        articles.append({
                            'title': item['title'],
                            'url': item['url'],
                            'source': item['source']['name'],
                            'published': item.get('publishedAt', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                        })
                else:
                    print(f"NewsAPI error {r.status_code}: {r.text} (query: {query[:50]}...)")
            except Exception as e:
                print(f"NewsAPI –æ—à–∏–±–∫–∞: {e}")

    # 2. RSS –∏–∑ –ö–∏—Ç–∞—è
    try:
        feeds = {
            'xinhua': 'http://www.xinhuanet.com/rss/world.xml',
            'sina': 'https://rss.sina.com.cn/news/china.xml',
            'sohu': 'http://rss.news.sohu.com/rss2/news.xml'
        }
        for name, feed_url in feeds.items():
            try:
                feed = feedparser.parse(feed_url)
                for entry in feed.entries:
                    title = entry.title.lower()
                    if any(kw.lower() in title for kw in ['metal', 'steel', 'technology', 'industry']):
                        articles.append({
                            'title': entry.title,
                            'url': entry.link,
                            'source': name,
                            'published': entry.get('published', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                        })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ RSS {name}: {e}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ RSS: {e}")

    return articles

# --- –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram ---
def send_message(chat_id, text, parse_mode='Markdown', disable_preview=False):
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    data = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": parse_mode,
        "disable_web_page_preview": disable_preview
    }
    try:
        requests.post(url, data=data, timeout=10)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")

# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ---
def main():
    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω (—Ä–µ–∂–∏–º GitHub Actions)")
    try:
        seen_urls = load_cache()
        raw_articles = search_news()
        print(f"–ü–æ–ª—É—á–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(raw_articles)}")

        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        filtered_articles = []
        for art in raw_articles:
            title = art['title'].lower()
            if any(kw.lower() in title for kw in ALL_KEYWORDS):
                filtered_articles.append(art)

        print(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(filtered_articles)}")

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏
        articles = [a for a in filtered_articles if a.get('url') not in seen_urls]

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 10‚Äì20 –Ω–æ–≤–æ—Å—Ç—è–º–∏
        if len(articles) < 10:
            selected = articles  # –º–µ–Ω—å—à–µ 10 ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ
        else:
            selected = articles[:20]  # –º–∞–∫—Å–∏–º—É–º 20

        print(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º: {len(selected)} –Ω–æ–≤–æ—Å—Ç–µ–π")

        if not selected:
            print("–ù–µ—Ç –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏.")
            return

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        msg = "üì¨ *–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç*\n\n"
        for art in selected:
            title_ru = translate_text(art['title'])
            source = art.get('source', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            msg += f"üìå *{title_ru}*\nüåê {source}\nüîó {art['url']}\n\n"

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–¥–º–∏–Ω—É
        if ADMIN_ID:
            send_message(ADMIN_ID, msg, disable_preview=True)

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à
        for art in selected:
            url = art.get('url')
            if url:
                seen_urls.add(url)
        save_cache(seen_urls)

        print("‚úÖ –†–∞—Å—Å—ã–ª–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)[:500]}"
        print(f"üî¥ –û—à–∏–±–∫–∞: {error_msg}")
        if ADMIN_ID:
            requests.post(
                f"https://api.telegram.org/bot{TOKEN}/sendMessage",
                data={"chat_id": ADMIN_ID, "text": f"‚ùå –û—à–∏–±–∫–∞: `{error_msg}`"}
            )

# --- –ó–∞–ø—É—Å–∫ ---
if __name__ == "__main__":
    main()